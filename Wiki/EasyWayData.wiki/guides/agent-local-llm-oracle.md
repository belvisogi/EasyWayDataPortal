---
id: ew-agent-local-llm-oracle
title: AI Agent Implementation Guide - Oracle Cloud + Ollama
summary: Guida pratica step-by-step per deployare stack completo AI agent (Ollama LLM + ChromaDB Vector DB + RAG pipeline) su Oracle Cloud Free Tier
owner: team-platform
status: active
tags: [domain/control-plane, layer/howto, audience/dev, audience/ops, privacy/internal, language/it, agents, llm, vector-db, rag, oracle-cloud, ollama, chromadb]
llm:
  include: true
  pii: none
  chunk_hint: 400-600
  redaction: []
entities: []
updated: 2026-01-26
next: Deploy su Oracle Cloud e testare prima esecuzione RAG
---

[[../start-here.md|Home]] > [[./agent-vectordb-architecture.md|Architecture]] > Implementation Guide

# üöÄ AI Agent Local LLM - Oracle Cloud Implementation

> **Filosofia**: "Foglio bianco = nuova visione. Un mattoncino alla volta, un JSON alla volta, un commit alla volta."

**Questa guida implementa l'architettura** descritta in:
- [Agent Vector DB Architecture](../control-plane/agent-vectordb-architecture.md) - Versione cloud (Azure AI Search)
- [Vector Memory Concept](../concept/vector-memory.md) - Rationale e concept

**Differenza chiave**: Questa √® la **versione locale low-cost** su Oracle Cloud Free Tier.

---

## üéØ Cosa Costruiamo

### Stack Tecnologico

```mermaid
graph TB
    subgraph "Oracle Cloud Free Tier"
        subgraph "AI Intelligence Stack"
            USER[üë§ User Query] --> ORCH[üé≠ Orchestrator<br/>PowerShell]
            ORCH --> RET[üîç Retrieval<br/>ChromaDB]
            ORCH --> LLM[üß† LLM<br/>Ollama DeepSeek]
            ORCH --> DB[üìä Database<br/>SQLite]
            
            RET -.->|Context| ORCH
            LLM -.->|Response| ORCH
            ORCH --> RESP[‚úÖ Enhanced Answer]
        end
        
        subgraph "Knowledge Sources"
            WIKI[üìö Wiki MD]
            CODE[üíª Code]
            RECIPES[üìã Recipes]
        end
    end
    
    WIKI --> RET
    CODE --> RET
    RECIPES --> RET
    
    style ORCH fill:#4CAF50
    style LLM fill:#2196F3
    style RET fill:#FF9800
    style DB fill:#9C27B0
```

### Componenti

| Layer | Tool | Funzione | Costo |
|-------|------|----------|-------|
| üß† **LLM** | Ollama + DeepSeek-R1 7B | Reasoning, decisioni | ‚Ç¨0 |
| üîç **Vector DB** | ChromaDB | Semantic search, RAG | ‚Ç¨0 |
| üìä **Persistence** | SQLite | Logs, metrics, audit | ‚Ç¨0 |
| üîß **Orchestration** | PowerShell + Python | Workflow management | ‚Ç¨0 |
| ‚òÅÔ∏è **Infrastructure** | Oracle Cloud Free Tier | Compute + storage | ‚Ç¨0 |

**Total**: ‚Ç¨0/mese üéâ

---

## üìã Prerequisites

### Infrastruttura
- ‚úÖ Oracle Cloud account con Free Tier attivo
- ‚úÖ Server VM Ubuntu ARM (4 cores, 24GB RAM)
- ‚úÖ Accesso SSH configurato

### Skills Richieste
- üîß Base Linux command line
- üêç Python (per ChromaDB)
- üíª PowerShell (per orchestrazione)

### Tempo Stimato
- ‚è±Ô∏è Setup completo: **2-3 ore**
- ‚úÖ Testing: **30 minuti**

---

## üöÄ Implementation - Step by Step

### FASE 1: Base System Setup (15 minuti)

#### 1.1 SSH al Server
```bash
ssh ubuntu@YOUR_ORACLE_IP
# O con chiave specifica:
# ssh -i ~/.ssh/oracle_key ubuntu@YOUR_ORACLE_IP
```

#### 1.2 Update Sistema
```bash
# Update packages
sudo apt update && sudo apt upgrade -y

# Install essentials
sudo apt install -y \
    build-essential \
    git \
    curl \
    wget \
    python3 \
    python3-pip \
    sqlite3 \
    htop \
    tmux
```

#### 1.3 Verifica Risorse
```bash
# Check RAM disponibile (serve ~10GB per Ollama)
free -h

# Check CPU cores
nproc

# Check disk space (serve ~20GB)
df -h

# Expected:
# RAM: ~24GB total, 20GB+ free
# CPU: 4 cores
# Disk: 200GB, ~180GB free
```

‚úÖ **Checkpoint**: Sistema aggiornato e risorse verificate

---

### FASE 2: Ollama Setup (15 minuti)

#### 2.1 Install Ollama
```bash
# Official install script
curl -fsSL https://ollama.com/install.sh | sh

# Verify installation
ollama --version
# Expected: ollama version 0.x.x
```

#### 2.2 Download Model DeepSeek-R1
```bash
# Pull model (4-5GB download, ~5-10 minuti)
ollama pull deepseek-r1:7b

# Verify download
ollama list
# Expected: deepseek-r1:7b    4.7 GB    ...
```

#### 2.3 Test LLM
```bash
# Interactive test
ollama run deepseek-r1:7b
```

**Test prompts**:
```
> What is RAG in AI?
> Explain Azure DevOps in 2 sentences
> exit
```

#### 2.4 Test API
```bash
# Test via API (per script automation)
curl http://localhost:11434/api/generate -d '{
  "model": "deepseek-r1:7b",
  "prompt": "Why is the sky blue?",
  "stream": false
}'

# Expected: JSON response con "response" field
```

‚úÖ **Checkpoint**: Ollama running e risponde intelligentemente

---

### FASE 3: PowerShell Setup (10 minuti)

#### 3.1 Install PowerShell on Linux
```bash
# Download Microsoft package
wget https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb

# Register repository
sudo dpkg -i packages-microsoft-prod.deb
sudo apt update

# Install PowerShell
sudo apt install -y powershell

# Verify
pwsh --version
# Expected: PowerShell 7.x.x
```

#### 3.2 Test PowerShell
```bash
pwsh

# Test comandi base
PS> Get-Date
PS> Get-Process | Select-Object -First 5
PS> $PSVersionTable
PS> exit
```

‚úÖ **Checkpoint**: PowerShell funzionante su Linux

---

### FASE 4: ChromaDB Vector DB Setup (20 minuti)

#### 4.1 Install Python ML Stack
```bash
# Upgrade pip
python3 -m pip install --upgrade pip

# Install ChromaDB
pip3 install chromadb

# Install sentence-transformers (embeddings)
pip3 install sentence-transformers

# Install utilities
pip3 install numpy pandas

# Verify installations
python3 -c "import chromadb; print('ChromaDB:', chromadb.__version__)"
python3 -c "from sentence_transformers import SentenceTransformer; print('sentence-transformers OK')"
```

#### 4.2 Create ChromaDB Manager Script
```bash
mkdir -p ~/easyway/scripts/ai-agent
nano ~/easyway/scripts/ai-agent/chromadb_manager.py
```

**File content** (`chromadb_manager.py`):
```python
#!/usr/bin/env python3
"""ChromaDB Manager for EasyWay AI Agent"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import json
import sys
from pathlib import Path

class KnowledgeBaseManager:
    def __init__(self, persist_dir="~/easyway-kb"):
        self.persist_dir = Path(persist_dir).expanduser()
        self.persist_dir.mkdir(parents=True, exist_ok=True)
        
        # ChromaDB client
        self.client = chromadb.PersistentClient(path=str(self.persist_dir))
        
        # Embedding model (all-MiniLM-L6-v2: fast, CPU-friendly)
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Collection
        self.collection = self.client.get_or_create_collection(
            name="easyway_knowledge",
            metadata={"description": "EasyWay agent knowledge base"}
        )
    
    def index_document(self, doc_path, doc_id=None):
        """Index a document into ChromaDB"""
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if doc_id is None:
            doc_id = f"doc_{Path(doc_path).stem}"
        
        # Generate embedding
        embedding = self.embedder.encode(content).tolist()
        
        # Add to collection
        self.collection.add(
            documents=[content],
            embeddings=[embedding],
            ids=[doc_id],
            metadatas=[{"filename": Path(doc_path).name, "path": str(doc_path)}]
        )
        
        print(f"‚úÖ Indexed: {doc_path}")
        return doc_id
    
    def search(self, query, top_k=3):
        """Semantic search"""
        query_embedding = self.embedder.encode(query).tolist()
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )
        
        return {
            "query": query,
            "results": [
                {
                    "doc_id": results['ids'][0][i],
                    "content": results['documents'][0][i],
                    "distance": results['distances'][0][i],
                    "metadata": results['metadatas'][0][i]
                }
                for i in range(len(results['ids'][0]))
            ]
        }

if __name__ == "__main__":
    kb = KnowledgeBaseManager()
    
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python3 chromadb_manager.py index <file>")
        print("  python3 chromadb_manager.py search '<query>'")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == "index":
        doc_path = sys.argv[2]
        kb.index_document(doc_path)
    
    elif command == "search":
        query = sys.argv[2]
        results = kb.search(query)
        print(json.dumps(results, indent=2))
```

Make executable:
```bash
chmod +x ~/easyway/scripts/ai-agent/chromadb_manager.py
```

#### 4.3 Test ChromaDB
```bash
# Create test document
echo "EasyWay is an AI-powered data portal for Azure governance. It helps manage Azure DevOps, databases, and data lakes through intelligent agents." > ~/test-doc.txt

# Index document
python3 ~/easyway/scripts/ai-agent/chromadb_manager.py index ~/test-doc.txt

# Search test
python3 ~/easyway/scripts/ai-agent/chromadb_manager.py search "What is EasyWay?"

# Expected: JSON con risultati rilevanti
```

‚úÖ **Checkpoint**: ChromaDB indicizza e cerca correttamente

---

### FASE 5: RAG Pipeline Orchestrator (30 minuti)

#### 5.1 Create Orchestrator Script
```bash
nano ~/easyway/scripts/ai-agent/rag_agent.ps1
```

**File content** (`rag_agent.ps1`):
```powershell
#!/usr/bin/env pwsh
<#
.SYNOPSIS
    AI Agent con RAG (Retrieval Augmented Generation)
.DESCRIPTION
    Workflow: Query ‚Üí Retrieval (ChromaDB) ‚Üí LLM (Ollama) ‚Üí Response ‚Üí Log
#>

param(
    [Parameter(Mandatory=$true)]
    [string]$Query,
    
    [int]$TopK = 3,
    [switch]$Verbose
)

$ErrorActionPreference = 'Stop'

Write-Host "ü§ñ EasyWay AI Agent with RAG" -ForegroundColor Cyan
Write-Host "Query: $Query`n" -ForegroundColor Yellow

# STEP 1: Retrieval
Write-Host "üîç STEP 1: Semantic Search..." -ForegroundColor Magenta

$retrievalCmd = "python3 ~/easyway/scripts/ai-agent/chromadb_manager.py search '$Query'"
$retrievalJson = Invoke-Expression $retrievalCmd
$retrieval = $retrievalJson | ConvertFrom-Json

$retrievedDocs = $retrieval.results | ForEach-Object {
    @{
        filename = $_.metadata.filename
        content = $_.content
        distance = $_.distance
        relevance = [math]::Round((1 - $_.distance), 2)
    }
}

if ($Verbose) {
    Write-Host "`nüìö Retrieved Documents:" -ForegroundColor DarkGray
    $retrievedDocs | ForEach-Object {
        Write-Host "  - $($_.filename) (relevance: $($_.relevance))" -ForegroundColor DarkGray
    }
}

# STEP 2: Context Preparation
Write-Host "`nüß† STEP 2: Preparing LLM prompt..." -ForegroundColor Magenta

$context = ($retrievedDocs | ForEach-Object {
    "Document: $($_.filename)`n$($_.content)`n---"
}) -join "`n"

$llmPrompt = @"
You are EasyWay AI Agent, expert on Azure DevOps and data governance.

CONTEXT from knowledge base:
$context

USER QUERY:
$Query

Provide accurate answer based on context. If insufficient, say so.
"@

# STEP 3: LLM Generation
Write-Host "`nüí¨ STEP 3: Querying LLM..." -ForegroundColor Magenta

$ollamaRequest = @{
    model = "deepseek-r1:7b"
    prompt = $llmPrompt
    stream = $false
} | ConvertTo-Json -Depth 10

$llmResponse = Invoke-RestMethod -Uri "http://localhost:11434/api/generate" `
    -Method Post `
    -Body $ollamaRequest `
    -ContentType "application/json"

$answer = $llmResponse.response

# STEP 4: Display
Write-Host "`n‚úÖ ANSWER:" -ForegroundColor Green
Write-Host $answer

# STEP 5: Log to SQLite
Write-Host "`nüìä STEP 5: Logging..." -ForegroundColor Magenta

$timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
$retrievedStr = ($retrievedDocs.filename -join ', ')

$dbPath = "$HOME/easyway.db"

# Create table if not exists
$createTableSql = @"
CREATE TABLE IF NOT EXISTS agent_executions (
    execution_id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL,
    query_text TEXT,
    retrieved_docs TEXT,
    llm_response TEXT,
    timestamp TEXT DEFAULT CURRENT_TIMESTAMP
);
"@

sqlite3 $dbPath $createTableSql

# Insert execution
$insertSql = @"
INSERT INTO agent_executions (agent_id, query_text, retrieved_docs, llm_response, timestamp)
VALUES ('rag_agent', '$($Query -replace "'", "''")', '$retrievedStr', '$($answer -replace "'", "''")', '$timestamp');
"@

sqlite3 $dbPath $insertSql

$executionId = sqlite3 $dbPath "SELECT last_insert_rowid();"
Write-Host "‚úÖ Logged execution #$executionId" -ForegroundColor Green

# Output structured result
@{
    execution_id = $executionId
    query = $Query
    retrieved_docs = $retrievedDocs.filename
    answer = $answer
    timestamp = $timestamp
} | ConvertTo-Json -Depth 5
```

Make executable:
```bash
chmod +x ~/easyway/scripts/ai-agent/rag_agent.ps1
```

‚úÖ **Checkpoint**: Orchestrator script creato

---

### FASE 6: Testing & Validation (30 minuti)

#### 6.1 Populate Knowledge Base
```bash
# Create sample knowledge base
mkdir -p ~/easyway/knowledge

# Document 1: About EasyWay
cat > ~/easyway/knowledge/easyway-intro.md <<'EOF'
# EasyWay Data Portal

EasyWay √® una piattaforma di governance dati enterprise per Azure.

## Features
- Agent AI per automazione
- Gestione multi-tenant
- Azure DevOps integration
- Data lake management
- Row-Level Security (RLS)

## Agent disponibili
- agent_dba: Database administration
- agent_ado_governance: Azure DevOps governance
- agent_security: Security  e audit
EOF

# Document 2: How to use agents
cat > ~/easyway/knowledge/agent-howto.md <<'EOF'
# Come Usare gli Agent

## Agent DBA
Per gestire database, usa:
- Script: agent-ado-governance.ps1
- Actions: ado:teams.list, ado:project.structure

## Export User Stories
Usa agent-ado-scrummaster.ps1 con:
- Action: ado:userstory.export
- Parametri: workItemType, query
EOF

# Index documents
python3 ~/easyway/scripts/ai-agent/chromadb_manager.py index ~/easyway/knowledge/easyway-intro.md
python3 ~/easyway/scripts/ai-agent/chromadb_manager.py index ~/easyway/knowledge/agent-howto.md
```

#### 6.2 Test Case 1: Query WITHOUT RAG (Baseline)
```bash
# Query LLM direttamente (no context)
curl http://localhost:11434/api/generate -d '{
  "model": "deepseek-r1:7b",
  "prompt": "How do I export user stories from EasyWay?",
  "stream": false
}' | jq -r '.response'

# Expected: Risposta generica, nessun dettaglio specifico EasyWay
```

#### 6.3 Test Case 2: Query WITH RAG (Enhanced)
```bash
pwsh ~/easyway/scripts/ai-agent/rag_agent.ps1 -Query "How do I export user stories from EasyWay?" -Verbose

# Expected:
# - Trova agent-howto.md
# - Risposta specifica con script name e parametri
# - Migliore qualit√† vs baseline!
```

#### 6.4 Verify Database Logging
```bash
# Query execution log
sqlite3 ~/easyway.db "SELECT * FROM agent_executions ORDER BY execution_id DESC LIMIT 5;"

# Expected: Vedi esecuzioni con query, docs retrieved, responses
```

#### 6.5 Compare Results
**Senza RAG**:
```
"To export user stories, you typically use an API or export tool. 
 Check your platform's documentation."
```

**Con RAG**:
```
"To export user stories from EasyWay, use the agent-ado-scrummaster.ps1 script.
 Execute with: -Action 'ado:userstory.export' -WorkItemType 'User Story' -Query '<your query>'.
 This is documented in the agent howto guide."
```

üéØ **RAG vince!** Risposta specifica, actionable, corretta!

‚úÖ **Checkpoint**: RAG funziona end-to-end!

---

## üìä Process Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant Orchestrator
    participant ChromaDB
    participant Ollama
    participant SQLite
    
    User->>Orchestrator: "How do I export user stories?"
    
    Orchestrator->>ChromaDB: Search("export user stories")
    ChromaDB->>ChromaDB: Embed query
    ChromaDB->>ChromaDB: Similarity search
    ChromaDB-->>Orchestrator: Top 3 docs (agent-howto.md, ...)
    
    Orchestrator->>Orchestrator: Prepare context
    Orchestrator->>Ollama: Prompt with context
    Ollama->>Ollama: Generate response
    Ollama-->>Orchestrator: "Use agent-ado-scrummaster..."
    
    Orchestrator->>SQLite: Log execution
    SQLite-->>Orchestrator: execution_id
    
    Orchestrator-->>User: Enhanced answer + sources
```

---

## üéâ Success Criteria

Dopo implementazione completa, verifica:

- [ ] ‚úÖ Ollama risponde a queries generiche
- [ ] ‚úÖ ChromaDB indicizza documenti
- [ ] ‚úÖ Semantic search trova docs rilevanti
- [ ] ‚úÖ RAG migliora qualit√† risposte vs LLM puro
- [ ] ‚úÖ SQLite logga tutte le esecuzioni
- [ ] ‚úÖ Orchestrator PowerShell funziona end-to-end
- [ ] ‚úÖ System usa <10GB RAM (~6-8GB)
- [ ] ‚úÖ Risposta totale <5 secondi

---

## üÜò Troubleshooting

### "Ollama: command not found"
```bash
# Riavvia shell
exit
ssh ubuntu@YOUR_ORACLE_IP
ollama --version
```

### "ChromaDB import error"
```bash
# Verifica installazione
pip3 list | grep chroma
# Re-install se necessario
pip3 install --upgrade chromadb
```

### "PowerShell: Invoke-RestMethod failed"
```bash
# Verifica Ollama running
curl http://localhost:11434/api/tags
# Restart se necessario
sudo systemctl restart ollama
```

### "Out of memory"
```bash
# Check RAM usage
free -h
# Se >20GB usati, restart process
ollama stop
ollama serve &
```

---

## üìà Next Steps

### Immediate (Post-Setup)
1. ‚úÖ Index pi√π documenti (Wiki completa,  code snippets)
2. ‚úÖ Tune chunking strategy (400-600 token chunks)
3. ‚úÖ Add more test cases

### Short Term (1-2 settimane)
4. ‚è≠Ô∏è Cron job per sync Git ‚Üí ChromaDB
5. ‚è≠Ô∏è Web UI per chat interface
6. ‚è≠Ô∏è Metrics dashboard (query success rate)

### Long Term (1+ mese)
7. ‚è≠Ô∏è Multi-agent orchestration
8. ‚è≠Ô∏è Deploy replica su Hetzner (comparison)
9. ‚è≠Ô∏è Production hardening (security, monitoring)

---

## üìö References

### Architettura
- [Agent Vector DB Architecture](../control-plane/agent-vectordb-architecture.md) - Cloud version (Azure AI Search)
- [Vector Memory Concept](../concept/vector-memory.md) - Rationale e theory
- [LLM Readiness Checklist](../llm-readiness-checklist.md) - Preparazione Wiki

### External Docs
- [Ollama Documentation](https://github.com/ollama/ollama)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [DeepSeek Model Card](https://github.com/deepseek-ai/DeepSeek-R1)

---

## üéì Lessons Learned

**Cosa abbiamo imparato costruendo questo**:

1. üß† **RAG > LLM Puro**: Context matters! LLM con knowledge base produce risposte molto migliori
2. üí∞ **‚Ç¨0 √® possibile**: Oracle Free Tier + Ollama + ChromaDB = stack enterprise a costo zero
3. ‚ö° **Performance OK**: 7B model su ARM √® pi√π che sufficiente per use case enterprise
4. üìö **Knowledge Base Quality**: Output dipende da input - documenta bene!
5. üîÑ **Iterazione Veloce**: Locale = test cycle velocissimo vs cloud API

---

**Created**: 2026-01-26  
**Author**: Team Platform  
**Status**: ‚úÖ Production Ready  
**Cost**: ‚Ç¨0/month  
**Next**: Deploy e goditi il viaggio! üöÄ

> *"Un mattoncino alla volta, un JSON alla volta, un commit alla volta... e costruiamo qualcosa di nuovo."*
